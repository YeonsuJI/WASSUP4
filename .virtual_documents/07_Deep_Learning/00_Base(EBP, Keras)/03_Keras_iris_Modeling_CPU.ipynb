


import warnings
warnings.filterwarnings('ignore')





import seaborn as sns

iris = sns.load_dataset('iris')





iris.info()


iris.head(3)








import tensorflow

tensorflow.__version__





import keras

keras.__version__











iris.species.value_counts()





X = iris[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']]
y = iris['species']

X.shape, y.shape








from sklearn.preprocessing import LabelEncoder

encoder =  LabelEncoder()
LBE_y = encoder.fit_transform(y)

LBE_y





from tensorflow.keras.utils import to_categorical

OHE_y = to_categorical(LBE_y)

OHE_y








from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, OHE_y, 
                                                    test_size = 0.3, 
                                                    random_state = 2045) 

X_train.shape, X_test.shape, y_train.shape, y_test.shape


X_train.head()








from tensorflow.keras import models 
from tensorflow.keras import layers








Model_iris = models.Sequential() # 순차적 모델

# Dense = Fully Connected layer
Model_iris.add(layers.Dense(16, activation = 'relu', input_shape = (4,)))
Model_iris.add(layers.Dense(8, activation = 'relu'))
Model_iris.add(layers.Dense(3, activation = 'softmax'))





Model_iris.summary()





from tensorflow.keras import utils

utils.plot_model(Model_iris,
                 show_shapes = True,
                 show_dtype = True)








Model_iris.compile(loss = 'categorical_crossentropy',
                   optimizer = 'adam',
                   metrics = ['accuracy'])








Model_iris.fit?


History_iris = Model_iris.fit(X_train, y_train,
                              epochs = 250,
                              batch_size = 7,
                              validation_data = (X_test, y_test))





import matplotlib.pyplot as plt

plt.figure(figsize = (9, 6))
plt.ylim(0, 1.1)
plt.plot(History_iris.history['loss'])
plt.plot(History_iris.history['val_loss'])
plt.plot(History_iris.history['accuracy'])
plt.plot(History_iris.history['val_accuracy'])
plt.legend(['loss', 'val_loss', 'accuracy', 'val_accuracy'])
plt.grid()
plt.show()








loss, accuracy = Model_iris.evaluate(X_test, y_test)

print('Loss = {:.5f}'.format(loss))
print('Accuracy = {:.5f}'.format(accuracy))








import numpy as np
np.set_printoptions(suppress = True, precision = 5)

Model_iris.predict(X_test)





y_hat = np.argmax(Model_iris.predict(X_test), axis = 1)

y_hat





y = np.argmax(y_test, axis = 1)

y





from sklearn.metrics import confusion_matrix, classification_report

confusion_matrix(y, y_hat)


print(classification_report(y, y_hat, 
                            target_names = ['setosa',
                                            'versicolor',
                                            'virginica']))











# !ls -l


Model_iris.save('Model_iris.h5')

# !ls -l





# from google.colab import files

# files.download('Model_iris.h5')





from tensorflow.keras.models import load_model

Model_local = load_model('Model_iris.h5')


np.argmax(Model_local.predict(X_test), axis = 1)








from google.colab import drive

drive.mount('/content/drive')





!ls -l '/content/drive/My Drive/Colab Notebooks/models'





Model_iris.save('/content/drive/My Drive/Colab Notebooks/models/001_Model_iris.h5')


!ls -l '/content/drive/My Drive/Colab Notebooks/models'





from tensorflow.keras.models import load_model

Model_google = load_model('/content/drive/My Drive/Colab Notebooks/models/001_Model_iris.h5')


np.argmax(Model_google.predict(X_test), axis = 1)



