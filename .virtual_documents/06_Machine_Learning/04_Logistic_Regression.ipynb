





import warnings
warnings.filterwarnings('ignore')





import numpy as np

def sigmoid(x):
    y_hat = 1 / (1 + np.exp(-x))
    return y_hat





sigmoid(0)


sigmoid(100000000)


sigmoid(-100000000)





import matplotlib.pyplot as plt

n = np.linspace(-10.0, 10.0, 2000)

plt.figure(figsize = (9, 6))
plt.plot(n, sigmoid(n))
plt.show()





import warnings
warnings.filterwarnings('ignore')








import pandas as pd

DF = pd.read_csv('https://raw.githubusercontent.com/rusita-ai/pyData/master/Default.csv')

DF.info()


DF.head()








DF.default.value_counts()





import matplotlib.pyplot as plt

plt.figure(figsize = (9, 6))
plt.boxplot([DF[DF.default == 'No'].balance,
             DF[DF.default == 'Yes'].balance],
            labels = ['No', 'Yes'])
plt.show()








X = DF[['balance']]
y = DF['default']








from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y,
                                                    test_size = 0.3,
                                                    random_state = 2045)

print('Train Data : ', X_train.shape, y_train.shape)
print('Test Data : ', X_test.shape, y_test.shape)








from sklearn.linear_model import LogisticRegression

Model_lr = LogisticRegression()
Model_lr.fit(X_train, y_train)





y_hat = Model_lr.predict(X_test)





y_hat 








from sklearn.metrics import confusion_matrix
confusion_matrix?


confusion_matrix(y_test, y_hat)





from sklearn.metrics import confusion_matrix

confusion_matrix(y_test, y_hat, labels = ['Yes','No'])





from sklearn.metrics import accuracy_score, precision_score, recall_score

print(accuracy_score(y_test, y_hat))
print(precision_score(y_test, y_hat, pos_label = 'No'))
print(recall_score(y_test, y_hat, pos_label = 'No'))





from sklearn.metrics import accuracy_score, precision_score, recall_score

print(accuracy_score(y_test, y_hat))
print(precision_score(y_test, y_hat, pos_label = 'Yes'))
print(recall_score(y_test, y_hat, pos_label = 'Yes'))





from sklearn.metrics import f1_score

f1_score(y_test, y_hat, pos_label = 'No')





from sklearn.metrics import f1_score

f1_score(y_test, y_hat, pos_label = 'Yes')





from sklearn.metrics import classification_report

print(classification_report(y_test, y_hat, 
                            target_names = ['No', 'Yes'],
                            digits = 5))





import warnings
warnings.filterwarnings('ignore')








# 각 사건이 발생할 확률
A = 0.9
B = 0.5
C = 0.1
# 가장 발생할 확률이 낮은 C가 정보량이 가장 높음
print('%.3f' % -np.log(A), '%.3f' % -np.log(B), '%.3f' % -np.log(C))





Alphago = 0.999
Apes = 0.001
# 알파고가 이겼을 때 놀람의 정도보다, 침팬지가 이겼을 때 놀람의 정도가 더 크다.
print('%.3f' % -np.log(Alphago), '%.3f' % -np.log(Apes))











P1 = 0.5
P2 = 0.5

-P1 * np.log(P1) - P2 * np.log(P2)





P1 = 0.999
P2 = 0.001

-P1 * np.log(P1) - P2 * np.log(P2)








import numpy as np

y = 1
y_hat = 1

-y * np.log(y_hat)





y = 1
y_hat = 0.0001

-y * np.log(y_hat)





y = 0
y_hat = 0

-(1 - y) * np.log(1 - y_hat)





y = 0
y_hat = 0.9999

-(1 - y) * np.log(1 - y_hat)



