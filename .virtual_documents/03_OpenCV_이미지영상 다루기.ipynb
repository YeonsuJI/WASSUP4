


pip install opencv-python


from tensorflow.keras.datasets import mnist
import cv2
import matplotlib.pyplot as plt


cv2.__version__


mnist.load_data?


(X_train, y_train), (X_test, y_test) = mnist.load_data()


type(X_train), X_train.dtype, X_train.ndim, X_train.shape, X_train.size


X_train[0]


y_train[0]


# 자동 제한없이 행렬 전체 출력
import sys
import numpy as np
# np.set_printoptions(threshold=np.inf, linewidth=np.inf) # 컴퓨터 성능에 영향을 줄 수 있으므로 주의 할 것
np.set_printoptions(linewidth = 150, precision = 2)


X_train[0]


X_train[1]





# from google.colab import drive
# drive.mount('/content/drive')


# pwd


from tensorflow.keras.datasets import mnist
import cv2
import numpy as np
import matplotlib.pyplot as plt


# 이미지 읽어오기
# img = cv2.imread('/content/car.jpg')
# img
path = 'C:/workspace/WASSUP4/data'
image = cv2.imread(path+'/car.jpg')  # BGR로 인식하므로 컨버팅 필요


image


cv2.imread?


type(image), image.dtype, image.ndim, image.shape, image.size


image[0]


plt.imshow(image)


# # 이미지 출력
# cv2.imshow('title', image) # 원본 출력
# cv2.waitKey(0)
# cv2.destroyAllWindows()





def imginfo(image):
    print(type(image), image.dtype, image.ndim, image.shape, image.size)


# bgr => rgb
image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # RGB로 컨버팅
plt.imshow(image)
# plt.show()# 객체 디스크립션 숨김
imginfo(image)


cv2.cvtColor?


# bgr => gray
gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
plt.imshow(gray) # cmap ='gray'
imginfo(gray)


gray[0], imginfo(gray[0])


# gray => colormap
im_color = cv2.applyColorMap(gray, cv2.COLORMAP_SUMMER)
plt.imshow(im_color)
imginfo(im_color)


hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
plt.imshow(hsv)
imginfo(hsv)





# 그린 색상 마스킹 = 크로마키
lower_green = np.array([0, 50, 0])
upper_green = np.array([100, 255, 100])

mask_green = cv2.inRange(hsv, lower_green, upper_green)
plt.imshow(mask_green)





height, width, channel = image.shape
height, width, channel


cv2.resize?


# 크기 조절
dst = cv2.resize(image, dsize=(320,187), interpolation=cv2.INTER_AREA) #interpolation 보간
imginfo(dst)
plt.imshow(dst)


# 확대, 축소
dst3 = cv2.pyrUp(image, dstsize=(width*2, height*2))
plt.imshow(dst3)
imginfo(dst3)
plt.show


cv2.pyrDown?


# 이미지 축소 메서드
dst4 = cv2.pyrDown(image)
plt.imshow(dst4)
imginfo(dst4)
plt.show()








plt.imshow(image)
imginfo(image)


dst5 = image[:375, :641]
plt.imshow(dst5)


# 가운데 중심점을 기준으로 50% 이미지 잘라내기
# 가운데 중심점 : height/2, width/2 , 시작위치 : height/2 – height/4    ,  끝위치: height/2 + height/4를 계산
#  image[y범위, x범위]

dst6 = image[int(height/2-height/4) : int(height/2+height/4),         # y 범위
             int(width/2-width/4)  : int(width/2+width/4)] # x범위
plt.imshow(dst6)


import tensorflow as tf
# IMAGE CROP
dst14 = tf.image.crop_to_bounding_box(image, 100, 200, 300, 400) # BOX좌표
# offset_height(위에서 아래로 +100), offset_width(좌에서 우방향으로 +200), target_height(offset지점에서부터 높이+300), target_width(offset지점부터 +400)
plt.imshow(dst14)





rows, cols, channels = image.shape
image.shape


cv2.warpAffine?


rows, cols, channels = image.shape

m = np.float32([[1,0,200],[0,1,100]]) # [x축 True, y축 false, 이동 200 ], [x축 false, y축 True, 이동 100]

dst = cv2.warpAffine(image, m, (cols,rows))

plt.imshow(dst)





cv2.getRotationMatrix2D?


# 중심점에서 30도 시계방향
M = cv2.getRotationMatrix2D((cols/2, rows/2), -30, 1)

rotate_30 = cv2.warpAffine(image, M, (cols,rows))

plt.imshow(rotate_30)





cv2.blur?


dst7 = cv2.blur(image, (20, 20)) # 값이 커질수록 더 흐려짐 , 필터의 컨벌루션
plt.imshow(dst7)


# 중앙값을 키워주는 형태의 마스크를 만든 후 적용하여 특징을 강조
# sharpening ; 주변 pixel과의 차이를 극대화시켜 경계부분의 명암비를 증가시키는 작업
# 주변부의 픽셀값을 감소시킬때, 강조될 강도를 mask중앙에 지정하고  주변부의 값을 줄여 총합이 1이 되도록 mask 생성
kernel = np.array([ [-1, -1, -1], [-1, 9, -1], [-1, -1, -1]    ]) # 필터 ,
dst8 = cv2.filter2D(image, -1, kernel) #두번째 인자인 depth은 출력영상의 데이터타입으로 default는 -1로 입력과 동일한 타입으로 출력
plt.imshow(dst8)


fig, ax = plt.subplots(1, 3, figsize = (20, 10))
ax[0].imshow(dst7)
ax[1].imshow(image)
ax[2].imshow(dst8)





# 상하 대칭
dst9 = cv2.flip(image, 0)
plt.imshow(dst9)


# 좌우 대칭
dst10 = cv2.flip(image, 1)
plt.imshow(dst10)


import tensorflow as tf
dst15 = tf.image.flip_left_right(image)
plt.imshow(dst15)





cv2.Canny?


dst11 = cv2.Canny(image, 500, 500) # (src, 작아질수록 엣지가 연결이 더 잘됨 , 작아질수록 엣지추출이 많아짐)
plt.imshow(dst11)


dst11 = cv2.Canny(image, 50, 500)
plt.imshow(dst11)


dst11 = cv2.Canny(image, 500, 50) #    (src, 작아질수록 엣지가 연결이 더 잘됨 , 작아질수록 엣지추출이 많아짐)
plt.imshow(dst11)


dst11 = cv2.Canny(image, 100, 100)
plt.imshow(dst11)





# 미변환하면 색상값이 BGR로 변경되므로 컨버팅 필요
# 변환전
cv2.imwrite('data/car_resize1.jpg', dst7)


# 변환 후
dst7_BGR = cv2.cvtColor(dst7, cv2.COLOR_BGR2RGB)
cv2.imwrite('data/car_resize2.jpg', dst7_BGR)





import os
print(os.getcwd())
print(os.listdir())


os.chdir(path)
print(os.getcwd())


img_folder_list = os.listdir() # /content/drive/MyDrive/Lecture/ESTsoft/WASSUP2기_교안/03_Data_Preprocessing/data
img_folder_list


import glob # 경로 가져오는 모듈
img_path = glob.glob('*.jpg') # 이미지폴더내 모든 이미지파일 경로
img_path


# 파일명 잘라오기
def file_name(path):
    # name = path.split('\\')[1].split('.')[0]
    name = path.split('.')[0]
    return name


for i in img_path:
    print(file_name(i))


import random
def rd_change(img):
    rows, cols, channels = img.shape
    rotate = random.randint(0,360)
    x_shift = random.randint(-100,100)
    y_shift = random.randint(-100,100)

    # move
    sm = np.float32([[1,0,x_shift],[0,1,y_shift]])
    img = cv2.warpAffine(img,sm,(cols,rows))

    # rotate
    rm = cv2.getRotationMatrix2D((cols/2,rows/2),rotate,1)
    img = cv2.warpAffine(img,rm,(cols,rows))

    return img


# 파일명 잘라오기
def file_name(path):
    # name = path.split('\\')[1]
    name = path.split('.')[0]
    return name


# 실행 및 이미지 저장
import cv2
import numpy as np
os.mkdir('result')

num = 0
for path in img_path:
    img = cv2.imread(path)
    rd_changed = rd_change(img)

    name = file_name(path)
    #cv2.imwrite('./result/'+name, rd_changed)
    cv2.imwrite('./result/'+name+'.jpg', rd_changed)
    num += 1
    print(num, path, '변환 저장 완료')
print('전체 이미지 변환 저장이 완료됐습니다.')
