


pip list





import requests
from bs4 import BeautifulSoup



PATH = "https://finance.naver.com/"
resp = requests.get(PATH)


resp


resp?


requests.get?


resp.text


print(resp.text)


html_src = resp.text


soup = BeautifulSoup(html_src, 'lxml')


## quiz  주요 뉴스의 목록들을 추출해보기
taglist = soup.select('.section_strategy a')
taglist


taglist = soup.select('.section_strategy li a')
len(taglist)



# 첫번째 뉴스 제목 추출
taglist[0].text


taglist[0]['href']


url = taglist[0]['href']
PATH = url


from urllib.parse import urljoin
urljoin(PATH,url)





news_title =[]
news_url = []

for tag in taglist:
    title = tag.text
    url = urljoin(PATH, tag['href'])
    print(title, url)
    news_title.append(title)
    news_url.append(url)


news_title


news_url


#데이터프레임 변환


import pandas as pd


df =pd.DataFrame({'제목':news_title, '주소':news_url})
df


#excel 파일 저장
df.to_excel?


pwd


df.to_excel('output/naver_finance.xlsx', index = False)


#파일명에다가 저장날짜 추가하기
import time


today = time.localtime()
today


today.tm_wday


time.ctime()


df.to_excel(f'output/{today.tm_year}_{today.tm_mon}_naver_finance.xlsx', index = False)


#yyyy-mm-dd
'%d-%02d-%02d'%(today.tm_year,today.tm_mon,today.tm_mday)


file_date = '%d-%02d-%02d'%(today.tm_year,today.tm_mon,today.tm_mday)
csv_name= file_date +'.csv'
csv_name


df.to_csv(f'output/{csv_name}')





import requests
from bs4 import BeautifulSoup
import pandas as pd


PATH = 'https://www.melon.com/chart/index.htm'
resp = requests.get(PATH)
resp


requests.get(PATH,'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36')


info = {'user-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36'}
info


resp = requests.get(PATH, headers =info)
resp


html_src = resp.text
html_src


# dom 객체 변환
soup = BeautifulSoup(html_src, 'lxml')
type(soup)


soup


#quiz 곡이름 찾기(객체)
len(soup.select('.ellipsis.rank01 a'))


title_list =[]
title = soup.select('.ellipsis.rank01 a')
for i in title:
    title_list.append(i.text)
title_list



title= [i.text for i in soup.select('.ellipsis.rank01 a')]
title





len(soup.select('.ellipsis.rank02 a'))


len(soup.select('div.ellipsis.rank02'))


len(soup.select('.checkEllipsis'))


artist = [i.text for i in soup.select('div.ellipsis.rank02')]
artist


artist = [i.text for i in soup.select('.checkEllipsis')]
artist


#순위 인덱스 만들기
rank = list(range(1,101))
print(rank)


songDF = pd.DataFrame({'순위':rank,'노래제목':title,'가수':artist})
songDF


songDF.to_csv('output/melon100.csv')





param =  {'name':'Amy' , 'age': 20, 'address': 'seoul'}


resp1 =requests.get('https://httpbin.org/get', params = param)
print(resp1)


print(resp1.text)


resp2 =requests.post('https://httpbin.org/post', data = param)
print(resp2)


print(resp2.text)  # post 는 데이터가 숨겨져서 나오기 떄문에 get이랑 다르게 주소에 나오는 args에 값이 나오지 않고 form에 값이 나온다. 





from bs4 import BeautifulSoup


PATH ='https://search.naver.com/search.naver?where=nexearch&sm=top_sug.asct&fbm=0&acr=3&acq=ai&qdt=0&ie=utf8&query=ai'
PATH


info = {'user-Agent':'https://search.naver.com/search.naver?where=nexearch&sm=top_sug.asct&fbm=0&acr=3&acq=ai&qdt=0&ie=utf8&query=ai'}
info


keyword = input('검색어를 입력하세요:')


resp = requests.get(PATH,params ={'query': keyword})
resp


html_src =resp.text
print(html_src)



soup = BeautifulSoup(html_src, 'lxml')
soup


title5= [i.text for i in soup.select('a.news_tit')]
title5


news_tit1 =[]
tit1 = soup.select('a.news_tit')
for i in  tit1:
    news_tit1.append(i.text)
news_tit1


result = soup.select('.news_tit')
print(len(result))
print(result)


for a in result:
    print(a.text, a['href'])





import requests
from bs4 import BeautifulSoup


PATH ='https://korean.visitkorea.or.kr/'
PATH


resp5 = requests.get('https://korean.visitkorea.or.kr/')
html_src = resp5.text


html_src


soup = BeautifulSoup(html_src, 'lxml')
soup


# 인기검색어와 url link까지 추출해보자
result = soup.select('.popular li a')
print(len(result))
print(result)









